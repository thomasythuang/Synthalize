<link rel="stylesheet" href="/css/visualizer.css">

<div class="navbar navbar-default navbar-static-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/#">Synthalize</a>
    </div>
    <div class="collapse navbar-collapse">
      <ul class="nav navbar-nav">
        <li><a href="/about">About</a></li>
        <li><a href="/future">Future Concept</a></li>
        <li><a href="/survey">Survey</a></li>
        <li><a href="/abstract.pdf" target="_blank">Abstract</a></li>
      </ul>
    </div>
  </div>
</div>

<div class="container panel panel-primary">
	<h1>Synthalize</h1>
	<p>This is our project for <a href="http://cs.northwestern.edu/~pardo/courses/eecs352/">EECS 352</a> with Bryan Pardo at Northwestern University. You can read our abstract <a href="/abstract.pdf" target="_blank">here</a> for more info or just <a href="/">try it out!</a></p>

	<div id="profiles" class="row">
		<div class="col-md-4">
			<strong>Ahren Alexander</strong><br>
			<a href="mailto:ahrenalexander2012@u.northwestern.edu" target="_blank">ahrenalexander2012@u.northwestern.edu</a>
		</div>
		<div class="col-md-4">
			<strong>Noah Conley</strong><br>
			<a href="mailto:noahkconley@gmail.com" target="_blank">noahkconley@gmail.com</a>
		</div>
		<div class="col-md-4">
			<strong>Thomas Huang</strong><br>
			<a href="mailto:thomashuang2016@u.northwestern.edu" target="_blank">thomashuang2016@u.northwestern.edu</a>
		</div>
	</div>

	<div class="text-center">
		<br>
		<iframe width="560" height="315" src="https://www.youtube.com/embed/gukDw1rgjTU" frameborder="0" allowfullscreen></iframe>
	</div>

	<h1>Introduction</h1>
	<div class="row">
		<div class="col-md-7">
			<p>In today's modern era, synthesizers are widely used by music professionals and casual musicians alike. However, all synthesizers share shortcomings on one area: finding and creating a desired sound. Whether analog or digital, synthesizers all have a "semantic gap" between the language used by the machine and the language used by the producer. While a user may desire a "warm" or "buzzy" sound, synthesizers have no adjustable parameters that can directly produce a similar sound using those adjectives. Many synthesizers do have factory preset settings to attempt to combat this, but they nearly all have nonsensical names such as "DramaQueen" or "Break it Down" that provide miminal help in finding an appropriate synthesizer setting. Because of this problem, it is often difficult, frustrating, and time-consuming to find a desired sound when using a synthesizer.</p>

			<h1>Our Solution</h1>
			<p>To solve that problem, we constructed an interface, Synthalize, that uses crowdsourced semantic data to enable synth patch selection via descriptive words instead of adjusting complicated parameters. Users search for words that describe the type of sound they desire, and when a word is selected, all synth patches matching that word are highlighted.</p>
		</div>
		<div class="col-md-5">
			<img class="col-md-12" src="img/synth.png">
			<div class="text-center">A traditional synthesizer interface and presets</div>
		</div>	
	</div>

	<h1>Process/Implementation</h1>
	<div class="row">
		<div class="col-md-6">
			<h4>Developing the Mechanical Turk Survey</h4>
			<ol>
				<li>Generate a simple 12-tone scale and chord for 48 different sound patches to play.</li>
				<li>Record each sound playing the scale and chord to a 12 second audio file.</li>
				<li>Within Mechanical Turk HIT, direct workers to <a href="/survey" target="_blank">our survey</a></li>
				<li>Ask workers to describe 4 random sounds from our bank of 48 using one or two words</li>
				<li>Workers are then provided a code to receive their compensation.</li>
			</ol>
			<p>150 workers completed this task resulting in 600 words or phrases used to describe our various sounds.  Several others (friends, peers, etc.) also completed the task outside of Mechanical Turk increasing the number of samples in our description database above 600.</p>
			<h4>Implementing the Synthesizer Interface</h4>
			<ol>
				<li>Use HTML, CSS, and Javascript to build a front-end interface for displaying our data</li>
				<li>The 600+ descriptions were incorporated into the synthesizer as “semantic tags” for users to search through in finding the sound their search queries are related to.  Using the <a href="http://words.bighugelabs.com/api.php" target="_blank">Big Huge Thesaurus API</a>, related semantic tags were also included in the descriptor database to help users find sounds described by words not found in our gathered data.  This increased the semantic tag count to 1500.</li>
				<li>The interface is separated into two sections:  tag searching and patch selection marked by blue and red respectively.  Users can hear a sample of a particular patch by clicking on its name in the patch selection area.  By searching for descriptors such as “dark” or “warm,” patch names change size in relation to their relevance to the search query.</li>
			</ol>
			<p>Additional tools and resources used to construct Synthalize included Massive by Native Instruments, Node.js, AngularJS, and Heroku</p>

		</div>
		<div class="col-md-6">
			<img class="col-md-12" src="img/survey.png">
			<div class="text-center">The Amazon Mechanical Turk survey</div>
		</div>
	</div>

	<h1>Testing and Results</h1>
	<p>Test subjects were asked to perform one of two versions of the same task.  Subjects were to select two sounds of our 48 that might find in an orchestra and then one sound they might find in a science fiction action film.  In the first version, subjects were not allowed to use the tag search functinoaltiy of the synthesizer, simulating the experience of using conventional synthesizer interfaces.  In the second version subjects were allowed to use the search functionality.  Subjects were timed on how long it took for them to pick sounds and were asked their satisfaction with their choices.</p>
	<p>Results proved inconclusive given remaining work to be done in developing the synthesizer interface.  During user testing and observation, subjects frequently skipped over using the search function altogether in favor of perusing the synth patch bank and sampling sounds one by one.  This was due to user frustration in receiving no results when searching for tags they felt were related to the task as well as the lack of emphasis by the interface of the importance of search functionality.  Even after reminding subjects about the semantic tag search function, they would often continue to explore the sound patch bank unassisted.  This is due to the bank only possessing only 48 sounds to choose from.  Commercially available synthesizers often have hundreds of factory presets users must sift through to find what they want.  With only 48 sounds displayed all at once (as opposed to the standard drop down menu), searching through synth patches did not require much effort.  By making it too easy for users to sort through all 48 sounds without the search function, the value of the semantic search function was ultimately trivial.</p>

	<div class="row">
		<div class="col-md-12">
			<h1>Conclusions and Future Work</h1>
			<p>Synthalize requires further development before the effectiveness of searching for sounds semantically can be determined; we believe the project holds great potential.  We succeeded in building a platform of our own, and glimmers of promise showed through during user observation.  When subjects searched for well-mapped tags in our database, Synthalize was very effective in isolating the types of sounds the user was looking for; however, too many search queries went unanswered, lacking a connection to the available synth patches.  The database of semantic tags requires expansion to account for the variance in descriptions of particular sounds.  Furthermore, the quality of data gathered needs to be more robust.  Some descriptions provided by Mechanical Turk workers proved inhibitive to the appropriate mapping of tags to sounds.  To avoid inhibitive responses, what makes an appropriate sound description needs to be more clearly defined.  In addition to more robust data gathering, the Synthalize interface requires a facelift to better communicate the purpose of its elements.  Provided in Figure 3 is a concept rendering of the next iteration of Synthalize and how it would appear to users.</p>
			<p>Ideally, Synthalize would evolve into a platform where low-level synthesis parameters could be controlled by high-level directives made by the user.  In order to get there, it will require further development of the user interaction experience, further semantic data collection, and greater exploration of the relationship between human language and sonic phenomena.</p>
		</div>
		<img class="col-md-8 col-md-offset-2" src="img/future-interface.png">
	</div>
	<div class="text-center">Rendering of a future interface concept</div>
</div>

